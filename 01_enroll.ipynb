{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a7dff17-fef9-4710-b253-d13b04f4c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\ppaudio-surveillance\n",
      "Folders created:\n",
      " - data/suspects\n",
      " - data/probes\n",
      " - models\n",
      " - artifacts\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib\n",
    "\n",
    "BASE = pathlib.Path.cwd()\n",
    "for p in [BASE / \"data\" / \"suspects\", BASE / \"data\" / \"probes\", BASE / \"models\", BASE / \"artifacts\"]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", BASE)\n",
    "print(\"Folders created:\\n - data/suspects\\n - data/probes\\n - models\\n - artifacts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f87d83-cbfe-43a3-87e6-fdc244a92fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:42:04) [MSC v.1943 64 bit (AMD64)]\n",
      "speechbrain 1.0.3\n",
      "librosa 0.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np, librosa, soundfile as sf\n",
    "import speechbrain as sb\n",
    "print(\"Python\", sys.version)\n",
    "print(\"speechbrain\", sb.__version__)\n",
    "print(\"librosa\", librosa.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6290f073-9d05-499a-9fc4-b3628b2de590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding extractor (ECAPA from SpeechBrain)\n",
    "#(this loads the pretrained model and defines helpers\n",
    "\n",
    "import torch\n",
    "from speechbrain.pretrained import EncoderClassifier\n",
    "import numpy as np\n",
    "import librosa, soundfile as sf\n",
    "from pathlib import Path\n",
    "\n",
    "# load the pretrained ECAPA TDNN speaker encoder\n",
    "encoder = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    run_opts={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    ")\n",
    "\n",
    "def load_audio_16k(path, target_sr=16000):\n",
    "    y, sr = librosa.load(path, sr=None, mono=True)\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "        sr = target_sr\n",
    "    return y, sr\n",
    "\n",
    "def wav_to_embedding(path):\n",
    "    y, sr = load_audio_16k(path)\n",
    "    # speechbrain expects torch tensor [batch, time]\n",
    "    import torch\n",
    "    signal = torch.tensor(y, dtype=torch.float32).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        emb = encoder.encode_batch(signal).squeeze(0).squeeze(0).cpu().numpy()\n",
    "    return emb  # 192-d vector for ECAPA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8670c331-cd2a-4194-9984-dc18888c2f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipywidgets: 8.1.7\n",
      "tqdm ok\n",
      "torch: 2.8.0+cpu\n",
      "torchaudio: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "#sanity Check\n",
    "\n",
    "\n",
    "import ipywidgets as widgets, tqdm, torch, torchaudio\n",
    "print(\"ipywidgets:\", widgets.__version__)\n",
    "print(\"tqdm ok\")\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchaudio:\", torchaudio.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f66a38f-02d1-44cc-8cfe-3de7380b112c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 wav files\n"
     ]
    }
   ],
   "source": [
    "#quick test (optional) — point to one of your WAVs:\n",
    "test_files = list((BASE / \"data\" / \"suspects\").rglob(\"*.wav\"))\n",
    "print(\"Found\", len(test_files), \"wav files\")\n",
    "if test_files:\n",
    "    e = wav_to_embedding(test_files[0])\n",
    "    print(\"Embedding shape:\", e.shape, \"example norm:\", np.linalg.norm(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d21a1fcc-3b46-41a0-a060-09e0d2886f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 0 enrolled speakers to D:\\ppaudio-surveillance\\artifacts\\suspects_embeddings.json\n"
     ]
    }
   ],
   "source": [
    "#enroll suspects (compute average embedding per person)\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "SUSPECTS_DIR = BASE / \"data\" / \"suspects\"\n",
    "ARTIFACTS = BASE / \"artifacts\"\n",
    "ARTIFACTS.mkdir(exist_ok=True)\n",
    "\n",
    "def enroll_suspects(suspects_dir=SUSPECTS_DIR):\n",
    "    speaker_embs = {}\n",
    "    for speaker_dir in sorted(p for p in suspects_dir.iterdir() if p.is_dir()):\n",
    "        wavs = sorted(speaker_dir.glob(\"*.wav\"))\n",
    "        if not wavs:\n",
    "            print(f\"[WARN] No wavs in {speaker_dir.name}, skipping.\")\n",
    "            continue\n",
    "        embs = []\n",
    "        for w in wavs:\n",
    "            try:\n",
    "                embs.append(wav_to_embedding(w))\n",
    "            except Exception as e:\n",
    "                print(f\"[ERR] {w.name}: {e}\")\n",
    "        if embs:\n",
    "            mean_emb = np.mean(np.stack(embs, axis=0), axis=0)\n",
    "            # l2-normalize (helps cosine)\n",
    "            mean_emb = mean_emb / (np.linalg.norm(mean_emb) + 1e-9)\n",
    "            speaker_embs[speaker_dir.name] = mean_emb.tolist()\n",
    "            print(f\"[OK] {speaker_dir.name}: {len(embs)} files -> enrolled.\")\n",
    "    # save\n",
    "    out = ARTIFACTS / \"suspects_embeddings.json\"\n",
    "    json.dump(speaker_embs, open(out, \"w\"))\n",
    "    print(f\"\\nSaved {len(speaker_embs)} enrolled speakers to {out}\")\n",
    "    return speaker_embs\n",
    "\n",
    "suspects = enroll_suspects()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b029c0e1-b5b4-493f-a764-11b0c689069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put a probe wav into data/probes and re-run.\n"
     ]
    }
   ],
   "source": [
    "#baseline identification (cosine similarity)\n",
    "#we’ll start with cosine scoring (simple), then you can swap to PLDA later if time permits.\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def cosine(a, b):\n",
    "    a = a / (np.linalg.norm(a) + 1e-9)\n",
    "    b = b / (np.linalg.norm(b) + 1e-9)\n",
    "    return float(np.dot(a, b))\n",
    "\n",
    "# load enrolled embeddings\n",
    "enrolled_path = ARTIFACTS / \"suspects_embeddings.json\"\n",
    "enrolled = json.load(open(enrolled_path))\n",
    "\n",
    "def identify_probe(wav_path, threshold=0.55):\n",
    "    probe_emb = wav_to_embedding(wav_path)\n",
    "    probe_emb = probe_emb / (np.linalg.norm(probe_emb) + 1e-9)\n",
    "    best_name, best_score = None, -1.0\n",
    "    for spk, emb_list in enrolled.items():\n",
    "        score = cosine(probe_emb, np.array(emb_list))\n",
    "        if score > best_score:\n",
    "            best_name, best_score = spk, score\n",
    "    verdict = best_name if best_score >= threshold else \"NO MATCH\"\n",
    "    return best_name, best_score, verdict\n",
    "\n",
    "# try it\n",
    "probe_files = sorted((BASE / \"data\" / \"probes\").glob(\"*.wav\"))\n",
    "if probe_files:\n",
    "    name, score, verdict = identify_probe(probe_files[0])\n",
    "    print(\"Best:\", name, \"score:\", round(score, 3), \"⇒\", verdict)\n",
    "else:\n",
    "    print(\"Put a probe wav into data/probes and re-run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd83603-eba6-4377-a176-48ce866ee5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0774413-99e5-4ac6-908b-f7038e7c781a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
